{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6ac3988f-d1dc-464c-b45f-b6dd578de1e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Jan 21 14:13:30 2025       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 550.127.05             Driver Version: 550.127.05     CUDA Version: 12.4     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  NVIDIA A100-SXM4-80GB          On  |   00000000:07:00.0 Off |                    0 |\n",
      "| N/A   28C    P0             59W /  400W |       1MiB /  81920MiB |      0%      Default |\n",
      "|                                         |                        |             Disabled |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|  No running processes found                                                             |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "546f6f3e-36d8-45c0-a4be-a34cf495d372",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Skipping transformers as it is not installed.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip uninstall transformers --yes #You'll need a special, different transformers\n",
    "!pip install -q -U datasets peft trl bitsandbytes transformers[torch] scipy tqdm scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "504ba811-79bf-4433-a747-4c53ac0806c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    _|    _|  _|    _|    _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|_|_|_|    _|_|      _|_|_|  _|_|_|_|\n",
      "    _|    _|  _|    _|  _|        _|          _|    _|_|    _|  _|            _|        _|    _|  _|        _|\n",
      "    _|_|_|_|  _|    _|  _|  _|_|  _|  _|_|    _|    _|  _|  _|  _|  _|_|      _|_|_|    _|_|_|_|  _|        _|_|_|\n",
      "    _|    _|  _|    _|  _|    _|  _|    _|    _|    _|    _|_|  _|    _|      _|        _|    _|  _|        _|\n",
      "    _|    _|    _|_|      _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|        _|    _|    _|_|_|  _|_|_|_|\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter your token (input will not be visible):  ········\n",
      "Add token as git credential? (Y/n)  n\n"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import interpreter_login\n",
    "interpreter_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3f593196-7cd2-426b-b40b-eb9a1c6477ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b47e96c753964638b6a0aa24db039536",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/609 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "393f5a658c05450696bc33b9ae50fb0e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors.index.json:   0%|          | 0.00/26.8k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe098eac54244188957128e1ce46fef0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "36d8dc2c21dd467dbde71a1704d2db2d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00002.safetensors:   0%|          | 0.00/9.98G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f9b3659c3a624087b064894147c2a0aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00002.safetensors:   0%|          | 0.00/3.50G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "677aeb1e1e3f4413aa50d1cfdb9a4a46",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c16fdf1afe3242219271904a1fb7f404",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/188 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "# Path to the checkpoint\n",
    "checkpoint_path = \"results/checkpoint-9500\"\n",
    "\n",
    "# Load the model\n",
    "model = AutoModelForCausalLM.from_pretrained(checkpoint_path)\n",
    "\n",
    "# Load the tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint_path)\n",
    "\n",
    "# Optional: Move the model to GPU\n",
    "model = model.to(\"cuda\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7938f1b9-024e-4e50-acd3-ca1101f37767",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_response(prompt, model, tokenizer, max_length=50, temperature=0.7, top_p=0.9):\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(\"cuda\")\n",
    "    outputs = model.generate(\n",
    "        **inputs,\n",
    "        max_length=max_length + len(inputs[\"input_ids\"][0]),\n",
    "        temperature=temperature,\n",
    "        top_p=top_p,\n",
    "    )\n",
    "    # Decode and remove the prompt from the response\n",
    "    full_response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    response = full_response[len(prompt):].strip()  # Strip the prompt part\n",
    "    return response\n",
    "\n",
    "# Example\n",
    "#prompt = \"Give me the location data that has most in common with the following address: Hyllie Kyrkoväg 47, Limhamn?\"\n",
    "#response = generate_response(prompt, model, tokenizer)\n",
    "#print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5722936e-3d62-4a52-8f5c-de0a7974ac52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac1bb58afa1746fab074c7383dc881d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "# Load the dataset\n",
    "dataset = load_dataset(\"json\", data_files=\"data10.jsonl\", split=\"train\")\n",
    "\n",
    "# Limit the dataset to the first 100 rows\n",
    "limited_dataset = dataset.select(range(min(100, len(dataset))))\n",
    "\n",
    "# Extract \"Assistant\" responses\n",
    "assistant_responses = [row[\"text\"].split(\"### Assistant:\")[1].strip() for row in limited_dataset]\n",
    "\n",
    "# Extract \"Human\" prompts\n",
    "human_prompts = [row[\"text\"].split(\"### Human:\")[1].split(\"### Assistant:\")[0].strip() for row in limited_dataset]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "87b76f53-1f52-4831-8a3b-92b3c366fcda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate and compare responses\n",
    "results = []\n",
    "for i, prompt in enumerate(human_prompts):\n",
    "    model_response = generate_response(prompt, model, tokenizer)\n",
    "    expected_response = assistant_responses[i]\n",
    "    results.append({\"Prompt\": prompt, \"Model Response\": model_response, \"Expected Response\": expected_response})\n",
    "\n",
    "# Optional: Print or save the results for analysis\n",
    "import pandas as pd\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df.to_csv(\"model_evaluation.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fdd34fb9-c2cf-4fad-8111-4b73f5b75664",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Average Similarity: 0.15820730278708858\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "def compute_similarity(responses):\n",
    "    vectorizer = TfidfVectorizer()\n",
    "    tfidf_matrix = vectorizer.fit_transform(responses)\n",
    "    similarities = cosine_similarity(tfidf_matrix[0:1], tfidf_matrix[1:]).flatten()\n",
    "    return similarities\n",
    "\n",
    "# Example for one comparison\n",
    "similarities = [\n",
    "    compute_similarity([row[\"Model Response\"], row[\"Expected Response\"]])[0]\n",
    "    for _, row in results_df.iterrows()\n",
    "]\n",
    "\n",
    "# Add similarities to the DataFrame\n",
    "results_df[\"Similarity\"] = similarities\n",
    "\n",
    "# Compute the total average similarity\n",
    "total_average_similarity = sum(similarities) / len(similarities) if similarities else 0\n",
    "\n",
    "# Add the total average similarity as a new column (if desired, for documentation purposes)\n",
    "results_df[\"Total Average Similarity\"] = total_average_similarity\n",
    "\n",
    "# Save the results to a CSV file\n",
    "results_df.to_csv(\"model_evaluation.csv\", index=False)\n",
    "\n",
    "print(f\"Total Average Similarity: {total_average_similarity}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a59359bf-56aa-4bea-840b-0745112d9134",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "\n",
    "def compute_precision_recall(model_response, expected_response):\n",
    "    vectorizer = CountVectorizer(binary=True)\n",
    "    response_matrix = vectorizer.fit_transform([model_response, expected_response])\n",
    "    response_array = response_matrix.toarray()\n",
    "    retrieved_words = set(vectorizer.get_feature_names_out(response_array[0] > 0))\n",
    "    relevant_words = set(vectorizer.get_feature_names_out(response_array[1] > 0))\n",
    "    \n",
    "    intersection = retrieved_words & relevant_words\n",
    "    precision = len(intersection) / len(retrieved_words) if retrieved_words else 0\n",
    "    recall = len(intersection) / len(relevant_words) if relevant_words else 0\n",
    "    \n",
    "    return precision, recall\n",
    "\n",
    "results_df[\"Precision\"] = results_df.apply(lambda row: compute_precision_recall(row[\"Model Response\"], row[\"Expected Response\"])[0], axis=1)\n",
    "results_df[\"Recall\"] = results_df.apply(lambda row: compute_precision_recall(row[\"Model Response\"], row[\"Expected Response\"])[1], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "314b6975-8325-40e3-9fab-1c03cc7173b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sentence_transformers\n",
      "  Downloading sentence_transformers-3.3.1-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (4.48.1)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (4.67.1)\n",
      "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (2.1.0+cu118)\n",
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (1.6.1)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (1.15.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.20.0 in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (0.27.1)\n",
      "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (9.3.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence_transformers) (3.9.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence_transformers) (2024.9.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence_transformers) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence_transformers) (6.0.1)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence_transformers) (2.32.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence_transformers) (4.12.2)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (1.12)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (3.0)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (3.1.2)\n",
      "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (2.1.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.41.0->sentence_transformers) (1.24.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.41.0->sentence_transformers) (2024.11.6)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.41.0->sentence_transformers) (0.21.0)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.41.0->sentence_transformers) (0.5.2)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence_transformers) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence_transformers) (3.5.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.11.0->sentence_transformers) (2.1.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.20.0->sentence_transformers) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.20.0->sentence_transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.20.0->sentence_transformers) (1.26.13)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.20.0->sentence_transformers) (2022.12.7)\n",
      "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.11.0->sentence_transformers) (1.3.0)\n",
      "Downloading sentence_transformers-3.3.1-py3-none-any.whl (268 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: sentence_transformers\n",
      "Successfully installed sentence_transformers-3.3.1\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install sentence_transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "73a1faf1-da5c-4788-b6c3-d3d36eb1ee60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f5164aa0f6a4f438460271b07720226",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modules.json:   0%|          | 0.00/229 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e4f023314a4d4a209e877b9c91fa9d75",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config_sentence_transformers.json:   0%|          | 0.00/122 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f868123703b04c849100797c63b2451d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/3.73k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2704944d1763471fb9daf9c02e031441",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a219fc20be841fc982b8fae3f2a6bf4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/629 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d26c628cc0b449599c52bd99a00db476",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "23305a92441e47159a18abf1e020fc90",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/314 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f203f46bfb3b4cfd8fb338f326180336",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "282aff93768243a5a6f8f79d44ae0f42",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aca03c2e78ed4e0aa148d121209531a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46380a1251234d779461a45c31732f1e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "1_Pooling/config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer, util\n",
    "\n",
    "model = SentenceTransformer('paraphrase-MiniLM-L6-v2')  # Load a pre-trained model\n",
    "\n",
    "def compute_faithfulness(model_response, expected_response):\n",
    "    response_embedding = model.encode(model_response, convert_to_tensor=True)\n",
    "    expected_embedding = model.encode(expected_response, convert_to_tensor=True)\n",
    "    similarity = util.cos_sim(response_embedding, expected_embedding).item()\n",
    "    return similarity\n",
    "\n",
    "results_df[\"Faithfulness\"] = results_df.apply(lambda row: compute_faithfulness(row[\"Model Response\"], row[\"Expected Response\"]), axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8a12aafa-afe3-4c31-b3ba-f84f889764a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_relevancy(question, model_response):\n",
    "    question_embedding = model.encode(question, convert_to_tensor=True)\n",
    "    response_embedding = model.encode(model_response, convert_to_tensor=True)\n",
    "    similarity = util.cos_sim(question_embedding, response_embedding).item()\n",
    "    return similarity\n",
    "\n",
    "results_df[\"Relevancy\"] = results_df.apply(lambda row: compute_relevancy(row[\"Prompt\"], row[\"Model Response\"]), axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5fabaaef-0f80-4212-9667-5c77ac86c6b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to CSV\n",
    "results_df.to_csv(\"model_evaluation_with_metrics.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6b4ed1c0-9570-422b-8022-0752663e426a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metrics:\n",
      "         Metric  Average Value\n",
      "0     Precision       1.000000\n",
      "1        Recall       1.000000\n",
      "2  Faithfulness       0.461719\n",
      "3     Relevancy       0.522230\n"
     ]
    }
   ],
   "source": [
    "# Compute averages for all metrics\n",
    "average_precision = results_df[\"Precision\"].mean()\n",
    "average_recall = results_df[\"Recall\"].mean()\n",
    "average_faithfulness = results_df[\"Faithfulness\"].mean()\n",
    "average_relevancy = results_df[\"Relevancy\"].mean()\n",
    "\n",
    "# Add these averages as a new row or save them separately\n",
    "average_metrics = {\n",
    "    \"Metric\": [\"Precision\", \"Recall\", \"Faithfulness\", \"Relevancy\"],\n",
    "    \"Average Value\": [average_precision, average_recall, average_faithfulness, average_relevancy]\n",
    "}\n",
    "\n",
    "import pandas as pd\n",
    "average_metrics_df = pd.DataFrame(average_metrics)\n",
    "\n",
    "# Save averages to a separate file or append to the same file\n",
    "average_metrics_df.to_csv(\"average_metrics.csv\", index=False)\n",
    "\n",
    "print(\"Average Metrics:\")\n",
    "print(average_metrics_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cf54f69d-1ea2-4e99-b91a-3662de22a7e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             Metric  Average Value\n",
      "0         Precision       1.000000\n",
      "1            Recall       1.000000\n",
      "2      Faithfulness       0.866660\n",
      "3  Answer Relevancy       0.962489\n"
     ]
    }
   ],
   "source": [
    "# Input values\n",
    "precision_values = [1, 1, 1, 1, 1]\n",
    "recall_values = [1, 1, 1, 1, 1]\n",
    "faithfulness_values = [0.8333, 0.5, 1, 1, 1]\n",
    "relevancy_values = [0.975, 0.9611, 0.956893, 0.959725, 0.959725]\n",
    "\n",
    "# Calculate averages\n",
    "average_precision = sum(precision_values) / len(precision_values)\n",
    "average_recall = sum(recall_values) / len(recall_values)\n",
    "average_faithfulness = sum(faithfulness_values) / len(faithfulness_values)\n",
    "average_relevancy = sum(relevancy_values) / len(relevancy_values)\n",
    "\n",
    "# Create a dictionary for results\n",
    "averages = {\n",
    "    \"Metric\": [\"Precision\", \"Recall\", \"Faithfulness\", \"Answer Relevancy\"],\n",
    "    \"Average Value\": [average_precision, average_recall, average_faithfulness, average_relevancy],\n",
    "}\n",
    "\n",
    "# Convert to DataFrame for display\n",
    "import pandas as pd\n",
    "averages_df = pd.DataFrame(averages)\n",
    "\n",
    "# Print the results\n",
    "print(averages_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2365fa83-5241-49a4-bee7-ebfe3b2f90cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             Metric  Average Value\n",
      "0         Precision          1.000\n",
      "1            Recall          1.000\n",
      "2      Faithfulness          0.950\n",
      "3  Answer Relevancy          0.958\n"
     ]
    }
   ],
   "source": [
    "# Input values\n",
    "precision_values = [1, 1, 1, 1, 1]\n",
    "recall_values = [1, 1, 1, 1, 1]\n",
    "faithfulness_values = [1, 0.75, 1, 1, 1]\n",
    "relevancy_values = [0.972, 0.932, 0.973, 0.972, 0.941]\n",
    "\n",
    "# Calculate averages\n",
    "average_precision = sum(precision_values) / len(precision_values)\n",
    "average_recall = sum(recall_values) / len(recall_values)\n",
    "average_faithfulness = sum(faithfulness_values) / len(faithfulness_values)\n",
    "average_relevancy = sum(relevancy_values) / len(relevancy_values)\n",
    "\n",
    "# Create a dictionary for results\n",
    "averages = {\n",
    "    \"Metric\": [\"Precision\", \"Recall\", \"Faithfulness\", \"Answer Relevancy\"],\n",
    "    \"Average Value\": [average_precision, average_recall, average_faithfulness, average_relevancy],\n",
    "}\n",
    "\n",
    "# Convert to DataFrame for display\n",
    "import pandas as pd\n",
    "averages_df = pd.DataFrame(averages)\n",
    "\n",
    "# Print the results\n",
    "print(averages_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75d3c465-415d-4d27-91db-0bc151cf2868",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
